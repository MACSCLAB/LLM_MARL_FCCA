import logging
import torch
import torch.nn as nn
import itertools
from ENVS.envs.utils.action import *
import numpy as np
from ENVS.envs.policy.cadrl import mlp
from ENVS.envs.policy.cadrl import CADRL
from ENVS.envs.utils.state_lux import Trans_OB

def build_action_space():
    speeds = [(np.exp((i + 1) / 5) - 1) / (np.e - 1) * 1 for i in range(5)]
    rotations = np.linspace(0, 2*np.pi, 16, endpoint=False)  # 均分
    action_sapce = [ActionXY(0, 0)]
    for rotation, speed in itertools.product(rotations, speeds):
        action_sapce.append(ActionXY(speed * np.cos(rotation), speed * np.sin(rotation)))
    return action_sapce

class PolicyNetwork(nn.Module): 
    def __init__(self, input_dim, robot_self_dim, robots_other_dim, mlp_dims, lstm_hidden_dim):
        super().__init__()
        self.robot_self_dim = robot_self_dim
        self.robots_other_dim = robots_other_dim
        self.lstm_hidden_dim = lstm_hidden_dim
        self.mlp_robot = mlp(robot_self_dim + robots_other_dim + lstm_hidden_dim, mlp_dims)
        self.lstm = nn.LSTM(input_dim, lstm_hidden_dim, batch_first=True)        
    
    def forward(self, state):
        # dg, v_pref, theta, radius, vx, vy, px2, py2, vx2, vy2, radius2 px1, py1, vx, vy, radius, da, radius_sum
        #  0    1      2       3      4   5   6    7   8   9     10      11    12  13  14   15     16     17   
        size = state.shape
        dim = state.dim
        if dim == 2:
            state = state.unsqueeze(0) 
            size = state.shape 
        robots_state = state[:, 0, :self.robot_self_dim + self.robots_other_dim]
        state_lstm = state
        h0 = torch.zeros(1, size[0], self.lstm_hidden_dim)
        c0 = torch.zeros(1, size[0], self.lstm_hidden_dim)
        output, (hn1, cn1) = self.lstm(state_lstm, (h0, c0))
        hn1 = hn1.squeeze(0)
        # logging.info('hn1:%s.', hn1)
        joint_state_with_robot = torch.cat([robots_state, hn1], dim=1)
        value = self.mlp_robot(joint_state_with_robot)
        return value

        
       

class Maac_RL(CADRL):
    def __init__(self):
        self.name = 'Maac_RL'
        self.kinematics = 'holonomic'

        self.with_interaction_module = None
        self.interaction_module_dims = None

        self.robot_self_dim = 6
        self.human_state_dim = 7
        self.robots_other_dim= 5 # (Agents_num -1) * 5 
        self.joint_state_dim = self.robot_self_dim + self.robots_other_dim + self.human_state_dim#6+5*(n-1)+7
    def configure(self, config):
        self.set_common_parameters(config)
        mlp_dims = [int(x) for x in config.get('multi_rl', 'mlp2_dims').split(', ')]
        global_dims =  config.getint('multi_rl', 'global_state_dim')#lstm
        self.with_om = config.getboolean('multi_rl', 'with_om')
        # with_interaction_module = config.getboolean('multi_rl', 'with_interaction_module')
        self.multiagent_training = config.getboolean('lstm_rl', 'multiagent_training')

        self.model = ValueNetwork(self.input_dim(), self.robot_self_dim, self.robots_other_dim, mlp_dims, global_dims)
        self.action_space = build_action_space()
    
    def reach_destination(self, state):
        dis = state[0,0]
        if dis < state[0, 3]:
            return True
        else:
            return False    
    def predict(self, state, no):
        
        if self.phase is None or self.device is None:
            raise AttributeError('Phase, device attributes have to be set!')

        if no == 0:
            state = self.transform(state, 0)
        if no == 1:         
            state = self.transform(state, 1)

        #state:
        # dg, v_pref, theta, radius, vx, vy, px2, py2, vx2, vy2, radius2 px1, py1, vx, vy, radius, da, radius_sum
        #  0    1      2       3      4   5   6    7   8   9     10      11    12  13  14   15     16     17   
        # N行17列的转换后的当前坐标下的机器人状态信息
        if self.reach_destination(state):
            return ActionXY(0, 0) if self.kinematics == 'holonomic' else ActionRot(0, 0) 
        if self.phase == 'train' and self.epsilon is None:
            raise AttributeError('Epsilon attribute has to be set in training phase')    
        if self.action_space is None:
            self.build_action_space(state[0,1])     

        probability = np.random.random()
        if self.phase == 'train' and probability < self.epsilon:
            max_action = self.action_space[np.random.choice(len(self.action_space))]
        else:
            self.robot_action_values = list()
            max_value = float('-inf')
            max_action = None
            for action in self.action_space:
                if self.query_env:#self-attention
                    if no == 0: 
                        next_states, reward, done, info = self.env.onestep_lookahead(action, ActionXY(0, 0))
                        next_self_state = self.propagate(next_states.robot1_state, action)
                        next_states.robot1_state = next_self_state
                    if no == 1:
                        next_states, reward, done, info = self.env.onestep_lookahead(ActionXY(0, 0), action)
                        next_self_state = self.propagate(next_states.robot2_state, action)
                        next_states.robot2_state = next_self_state

                next_states= self.transform(next_states, no)

                # logging.info('%s', action)
                next_states = next_states.unsqueeze(0)
                next_state_value = self.model(next_states.to(self.device))
                next_state_value = next_state_value.data.item()
                # logging.info('%s', next_states)
                # logging.info('%s', next_state_value)
                value = reward[no] + pow(self.gamma, self.time_step * state[0, 1]) * next_state_value
                    # self.robot1_action_values.append(value_1)
                if value > max_value:
                    max_value = value
                    max_action = action
                if max_action is None:
                    raise ValueError('Value network is not well trained. ')    
        return max_action                                       

    def transform(self, state, no):
        
        state = self.ob_trans(state, no)
        state_robot_tensor = torch.cat([torch.Tensor([state.robot_self_state + state.robots_other_state+ 
                                        (human_state.px, human_state.py, human_state.vx, human_state.vy, human_state.radius)]).to(self.device)
                                         for human_state in state.human_states], dim=0)

        state_robot_tensor = self.rotate(state_robot_tensor)

        return state_robot_tensor  
     
    def ob_trans(self, state, no):
        if no == 0:
            ob = Trans_OB(state.robot1_state, state.robot2_state, state.human_states)
            # logging.info('vxvxvxvx::::::::::%s',ob.robots_other_state.py)
        if no == 1:
            ob = Trans_OB(state.robot2_state, state.robot1_state, state.human_states)
        return ob
        
                    
    def rotate(self, state):

        #robot_self
        # 'px', 'py', 'vx', 'vy', 'radius', 'gx', 'gy', 'v_pref', 'theta'
        # 0     1      2     3      4        5     6      7         8
        #robot_others
        #'px', 'py', 'vx', 'vy', 'radius', 'gx', 'gy', 'v_pref', 'theta'
        # 9     10     11     12     13     14    15      16        17
        # 'px1', 'py1', 'vx1', 'vy1', 'radius1'
        #   18     19     20     21       22

        batch = state.shape[0]



        dx = (state[:, 5] - state[:, 0]).reshape((batch, -1))  
        dy = (state[:, 6] - state[:, 1]).reshape((batch, -1))
        rot = torch.atan2(state[:, 6] - state[:, 1], state[:, 5] - state[:, 0])  # arctan (y/x)

        dg = torch.norm(torch.cat([dx, dy], dim=1), 2, dim=1, keepdim=True)
        v_pref = state[:, 7].reshape((batch, -1))

        #以当前位置与终点间连线作为横坐标重新建系
        vx = (state[:, 2] * torch.cos(rot) + state[:, 3] * torch.sin(rot)).reshape((batch, -1))
        vy = (state[:, 3] * torch.cos(rot) - state[:, 2] * torch.sin(rot)).reshape((batch, -1))

        radius = state[:, 4].reshape((batch, -1))
        if self.kinematics == 'unicycle':
            theta = (state[:, 8] - rot).reshape((batch, -1))
        else:
            # set theta to be zero since it's not used
            theta = torch.zeros_like(v_pref)
        vx1 = (state[:, 20] * torch.cos(rot) + state[:, 21] * torch.sin(rot)).reshape((batch, -1))
        vy1 = (state[:, 21] * torch.cos(rot) - state[:, 20] * torch.sin(rot)).reshape((batch, -1))
        px1 = (state[:, 18] - state[:, 0]) * torch.cos(rot) + (state[:, 19] - state[:, 1]) * torch.sin(rot)
        px1 = px1.reshape((batch, -1))
        py1 = (state[:, 19] - state[:, 1]) * torch.cos(rot) - (state[:, 18] - state[:, 0]) * torch.sin(rot)
        py1 = py1.reshape((batch, -1))
        #robot other
        px2 = (state[:, 9] - state[:, 0]) * torch.cos(rot) + (state[:, 10] - state[:, 1]) * torch.sin(rot)
        px2 = px2.reshape((batch, -1))
        py2 = (state[:, 10] - state[:, 1]) * torch.cos(rot) - (state[:, 9] - state[:, 0]) * torch.sin(rot)
        py2 = py2.reshape((batch, -1))
        vx2 = (state[:, 11] * torch.cos(rot) + state[:, 12] * torch.sin(rot)).reshape((batch, -1))
        vy2 = (state[:, 12] * torch.cos(rot) - state[:, 11] * torch.sin(rot)).reshape((batch, -1))       
        radius2 = state[:, 13].reshape((batch, -1))
        radius1 = state[:, 22].reshape((batch, -1))
        radius_sum = radius + radius1
        da = torch.norm(torch.cat([(state[:, 0] - state[:, 18]).reshape((batch, -1)), (state[:, 1] - state[:, 19]).
                                  reshape((batch, -1))], dim=1), 2, dim=1, keepdim=True)
        new_state = torch.cat([dg, v_pref, theta, radius, vx, vy, px2, py2, vx2, vy2, radius2, px1, py1, vx1, vy1, radius1, da, radius_sum], dim=1)
        # vx1 = (state[:, 20] * torch.cos(rot) - state[:, 20] * torch.cos(rot)).reshape((batch, -1))
        # vy1 = (state[:, 20] * torch.cos(rot) - state[:, 20] * torch.cos(rot)).reshape((batch, -1))
        # px1 = (state[:, 18] - state[:, 18]) * torch.cos(rot) + (state[:, 19] - state[:, 19]) * torch.sin(rot)
        # px1 = px1.reshape((batch, -1))
        # py1 = (state[:, 19] - state[:, 19]) * torch.cos(rot) - (state[:, 18] - state[:, 18]) * torch.sin(rot)
        # py1 = py1.reshape((batch, -1))
        # da = torch.norm(torch.cat([(state[:, 0] - state[:, 0]).reshape((batch, -1)), (state[:, 1] - state[:, 1]).
        #                           reshape((batch, -1))], dim=1), 2, dim=1, keepdim=True)        
        # radius1 = (state[:, 22]-state[:, 22]).reshape((batch, -1))
        # new_state = torch.cat([dg, v_pref, theta, radius, vx, vy, px2, py2, vx2, vy2, radius2, px1, py1, vx1, vy1, radius1, da, radius_sum], dim=1)
        # dg, v_pref, theta, radius, vx, vy, px2, py2, vx2, vy2, radius2 px1, py1, vx, vy, radius, da, radius_sum
        #  0    1      2       3      4   5   6    7   8   9     10      11    12  13  14   15     16     17   
        # N行17列的转换后的当前坐标下的机器人状态信息

        return new_state
    
    def load_model(self, model):
        self.model = model
    def set_device(self, device):
        self.device = device
        self.model.to(device)